{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6754efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: (60000, 28, 28)\n",
      "Train Labels Length: 60000\n",
      "Test Images Shape: (10000, 28, 28)\n",
      "Test Labels Length: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.layers import (Dense, Activation, Flatten, Dropout, Conv2D, Conv2DTranspose,\n",
    "                                     MaxPooling2D, LeakyReLU, Input)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from scikeras.wrappers import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "data = mnist.load_data\n",
    "\n",
    "# Display information about the dataset\n",
    "print(\"Train Images Shape:\", x_train.shape)\n",
    "print(\"Train Labels Length:\", len(y_train))\n",
    "print(\"Test Images Shape:\", x_test.shape)\n",
    "print(\"Test Labels Length:\", len(y_test))\n",
    "\n",
    "# Visualize a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title(f\"Label: {y_train[0]}\")\n",
    "plt.show()\n",
    "\n",
    "# Reshape and normalize the input data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test= to_categorical(y_test)\n",
    "\n",
    "seed_value = 42\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d860a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(batch_size, noise_dim):\n",
    "    return np.random.normal(0, 1, size=(batch_size, noise_dim)).astype(np.float32)\n",
    "\n",
    "def create_gen(base, noise_dim, target_shape):\n",
    "    gen = base\n",
    "    \n",
    "    gen.add(Dense(196, input_dim=noise_dim))\n",
    "    #gen.add(layers.LeakyReLU())\n",
    "    gen.add(Dense(784, activation = 'relu'))\n",
    "    gen.add(Dense(1568, activation = 'sigmoid'))\n",
    "    gen.add(layers.Reshape((7, 7, 32)))\n",
    "    \n",
    "    gen.add(Conv2DTranspose(128, kernel_size=1, strides = (1, 2), padding='same'))\n",
    "    assert gen.output_shape == (None, 7, 14, 128), f'Model Shape {gen.output_shape}'\n",
    "    \n",
    "    gen.add(Conv2DTranspose(128, kernel_size=1, strides = (2, 1), padding='same'))\n",
    "    assert gen.output_shape == (None, 14, 14, 128), f'Model Shape {gen.output_shape}'\n",
    "    \n",
    "    gen.add(Conv2DTranspose(128, kernel_size=3, strides = (2, 1), padding='same'))\n",
    "    assert gen.output_shape == (None, 28, 14, 128), f'Model Shape {gen.output_shape}'\n",
    "    gen.add(layers.BatchNormalization())\n",
    "\n",
    "    gen.add(Conv2DTranspose(128, kernel_size=3, strides = (1, 2), padding='same'))\n",
    "    assert gen.output_shape == (None, 28, 28, 128), f'Model Shape {gen.output_shape}'\n",
    "    gen.add(layers.BatchNormalization())    \n",
    "    \n",
    "    gen.add(Conv2DTranspose(128, kernel_size=3, strides = (1, 1), padding='same'))\n",
    "    assert gen.output_shape == (None, 28, 28, 128), f'Model Shape {gen.output_shape}'\n",
    "    #gen.add(layers.BatchNormalization())\n",
    "\n",
    "    gen.add(Conv2DTranspose(128, kernel_size=4, strides = 1, padding='same'))\n",
    "    gen.add(layers.BatchNormalization())\n",
    "\n",
    "    #gen.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, \n",
    "     #                                activation = 'tanh'))\n",
    "    gen.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, \n",
    "                                     activation = 'sigmoid'))\n",
    "    assert gen.output_shape == (None, 28, 28, 1), f'Model Shape {model.output_shape}'\n",
    "    \n",
    "    return gen\n",
    "\n",
    "def create_disc(base, target_shape):\n",
    "    discriminator = base\n",
    "    discriminator.add(Conv2D(filters=64, kernel_size=(2, 2), padding='same', input_shape=target_shape, strides=(2,1)))\n",
    "    discriminator.add(Dropout(rate=0.2))\n",
    "    discriminator.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    discriminator.add(Conv2D(filters=64, kernel_size=(2, 2), padding='same', strides=(1,2)))\n",
    "    discriminator.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=128, kernel_size=(2, 2), padding='same', strides=(1,1)))\n",
    "    #discriminator.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    \n",
    "    discriminator.add(layers.Flatten())\n",
    "    discriminator.add(layers.Dense(512))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(rate=0.2))\n",
    "    discriminator.add(Dense(256))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dense(128))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(rate=0.2))\n",
    "    discriminator.add(Dense(64))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return discriminator\n",
    "    \n",
    "\n",
    "def create_gan(gen, disc):\n",
    "    disc.trainable = False\n",
    "    \n",
    "    return gan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2660295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 128\n",
    "noise_dim = 50\n",
    "target_shape = (28, 28, 1)\n",
    "\n",
    "seq = Sequential()\n",
    "noise = generate_noise(batch_size, noise_dim)\n",
    "\n",
    "gen = create_gen(seq, noise_dim, target_shape)\n",
    "gen.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "disc = create_disc(seq, target_shape)\n",
    "disc.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60e8bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_79 (Dense)            (None, 196)               9996      \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 784)               154448    \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1568)              1230880   \n",
      "                                                                 \n",
      " reshape_18 (Reshape)        (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_65 (Conv2  (None, 7, 14, 128)        4224      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_66 (Conv2  (None, 14, 14, 128)       16512     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_67 (Conv2  (None, 28, 14, 128)       147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 28, 14, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_68 (Conv2  (None, 28, 28, 128)       147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 28, 28, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_69 (Conv2  (None, 28, 28, 128)       147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_70 (Conv2  (None, 28, 28, 128)       262272    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 28, 28, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_71 (Conv2  (None, 28, 28, 1)         3200      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 28, 64)        320       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 14, 28, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 28, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 14, 64)         16448     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 128)         32896     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 512)               3211776   \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5559805 (21.21 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 5559805 (21.21 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_79 (Dense)            (None, 196)               9996      \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 784)               154448    \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1568)              1230880   \n",
      "                                                                 \n",
      " reshape_18 (Reshape)        (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_65 (Conv2  (None, 7, 14, 128)        4224      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_66 (Conv2  (None, 14, 14, 128)       16512     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_67 (Conv2  (None, 28, 14, 128)       147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 28, 14, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_68 (Conv2  (None, 28, 28, 128)       147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 28, 28, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_69 (Conv2  (None, 28, 28, 128)       147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_70 (Conv2  (None, 28, 28, 128)       262272    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 28, 28, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_71 (Conv2  (None, 28, 28, 1)         3200      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_6 (Conv2D)           (None, 14, 28, 64)        320       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 14, 28, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 28, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 14, 64)         16448     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 128)         32896     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 512)               3211776   \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5559805 (21.21 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 5559805 (21.21 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen.summary()\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4de52be4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_26\" (type Sequential).\n\nInput 0 of layer \"dense_79\" is incompatible with the layer: expected axis -1 of input shape to have value 50, but received input with shape (None, 1)\n\nCall arguments received by layer \"sequential_26\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-49cf9e132492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnoise_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvalidity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create the GAN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 }:\n\u001b[0;32m--> 280\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    281\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_26\" (type Sequential).\n\nInput 0 of layer \"dense_79\" is incompatible with the layer: expected axis -1 of input shape to have value 50, but received input with shape (None, 1)\n\nCall arguments received by layer \"sequential_26\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Disable training for the discriminator during GAN training\n",
    "disc.trainable = False\n",
    "\n",
    "# Connect the generator and discriminator\n",
    "noise_input = Input(shape=(noise_dim,))\n",
    "generated_image = gen(noise_input)\n",
    "validity = disc(generated_image)\n",
    "\n",
    "# Create the GAN model\n",
    "gan = Model(noise_input, validity)\n",
    "\n",
    "# Compile the GAN model\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
